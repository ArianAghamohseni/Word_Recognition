{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed5a720b-af17-4312-b543-71f603ddfa23",
   "metadata": {
    "id": "04ab4fbd-f191-427a-a2e4-db4ff76fa385"
   },
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c40530b-0436-4965-908d-e709114e316b",
   "metadata": {
    "executionInfo": {
     "elapsed": 3102,
     "status": "ok",
     "timestamp": 1651313252929,
     "user": {
      "displayName": "Arash Dadras",
      "userId": "05722346836148265544"
     },
     "user_tz": -270
    },
    "id": "42e504d1-66bf-459a-bdee-ef0f268a7b81",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.getcwd())))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cmdstanpy \n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import arviz as az\n",
    "import json\n",
    "from utils.random import random_rdm_2A\n",
    "from utils.utils import get_dfs, calculate_waic, bci, plot_mean_posterior\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fda25d-8c73-4076-a32e-b9f64a89752d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.rcParams[\"font.serif\"] = [\"Times New Roman\"] + plt.rcParams[\"font.serif\"]\n",
    "plt.rcParams[\"pdf.fonttype\"] = 42\n",
    "plt.rcParams[\"pdf.use14corefonts\"] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf5ed11-783c-476d-b190-95c7356783ca",
   "metadata": {},
   "source": [
    "## Choose Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d5ad7e-f13d-41a9-a8d5-528f99513a33",
   "metadata": {},
   "source": [
    "#### roots and global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c30c41-a570-411a-a874-36f0776f87f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root = \"../\"\n",
    "plots_root = \"Results/individual/Plots/\"\n",
    "datasets_root = root + \"Datasets/\"\n",
    "behavioural_data_root = datasets_root +  \"behavioral_data/selected_data/\" \n",
    "stan_files_root = root +  \"models/stan/\" \n",
    "saved_models_root = \"Results/individual/stan_results/\"\n",
    "\n",
    "model_config = {}\n",
    "plots_path = \"\"\n",
    "dataset_path = \"\"\n",
    "stan_file_path = \"\"\n",
    "stan_output_dir = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fddb96-7bae-4d47-a322-e42e6285e69e",
   "metadata": {},
   "source": [
    "#### read models configuration json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272c3c67-1630-4266-9163-296e244195b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"../models/rdm_based_models.json\") as f:\n",
    "    models = json.load(f)\n",
    "    models_name = list(models.keys())\n",
    "    models_name = list(\n",
    "        filter(lambda model_name: \"individual\" in model_name,\n",
    "               models_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5768a530-f38b-4267-9084-5ba80a1471af",
   "metadata": {},
   "source": [
    "#### Choose and set model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8122cea8-7777-4a9c-98be-4fea9b2dfcab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def SetModelAndPaths(model_name):\n",
    "    global model_config\n",
    "    global plots_path\n",
    "    global dataset_path\n",
    "    global stan_file_path\n",
    "    global stan_output_dir\n",
    "    model_config = models[model_name]\n",
    "    plots_path = plots_root + model_config[\"plots_folder_name\"] + \"/\"\n",
    "    dataset_path = datasets_root + \"AI Models Results/\" + model_config[\"dataset_name\"]\n",
    "    stan_file_path = stan_files_root + model_config[\"stan_file\"]\n",
    "    stan_output_dir = saved_models_root + model_config[\"model_name\"] + \"/\"\n",
    "    \n",
    "    if not os.path.exists(plots_path):\n",
    "        os.makedirs(plots_path)\n",
    "        print(\"Directory \" , plots_path ,  \" Created \")\n",
    "    else:    \n",
    "        print(\"Directory \" , plots_path ,  \" already exists\")\n",
    "        \n",
    "    if not os.path.exists(stan_output_dir):\n",
    "        os.makedirs(stan_output_dir)\n",
    "        print(\"Directory \" , stan_output_dir ,  \" Created \")\n",
    "    else:    \n",
    "        print(\"Directory \" , stan_output_dir ,  \" already exists\")\n",
    "\n",
    "widgets.interact(SetModelAndPaths, model_name=models_name);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3e1780-916e-4904-a2d3-389b27227c49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e617f6",
   "metadata": {
    "id": "123c4809-7b46-4f8d-b578-0d5e9fb5fbe7",
    "tags": []
   },
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d41247-a08b-4710-a8cb-006ca5ace314",
   "metadata": {},
   "source": [
    "Loading words and non-words with zipf and predicted probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6417ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 61,
     "status": "ok",
     "timestamp": 1651313252934,
     "user": {
      "displayName": "Arash Dadras",
      "userId": "05722346836148265544"
     },
     "user_tz": -270
    },
    "id": "72172233-0e82-4058-8a5c-8657e9fe4693",
    "outputId": "35336463-3bb2-41e5-c84f-7c34fdcfc77d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "word_nword_df = pd.read_csv(dataset_path, header=None,\n",
    "                            names =[\"string\", \"freq\",  \"label\", \"zipf\",\n",
    "                                    \"category\", \"word_prob\", \"non_word_prob\"])\n",
    "word_nword_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb6266a",
   "metadata": {
    "executionInfo": {
     "elapsed": 56,
     "status": "ok",
     "timestamp": 1651313252938,
     "user": {
      "displayName": "Arash Dadras",
      "userId": "05722346836148265544"
     },
     "user_tz": -270
    },
    "id": "f37d4118-f2ea-4691-bff9-02f1ac1cebbc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reading LDT Data\n",
    "behavioural_df = pd.read_csv(behavioural_data_root + \"LDT_data.csv\",\n",
    "                             header=None,\n",
    "                             names=[\"accuracy\", \"rt\", \"string\", \"response\",\n",
    "                                    \"participant\", \"minRT\", \"participant_id\"])\n",
    "# Merging  behavioral dataframe with word_nonword_df to have words and non-words data with behavioral data\n",
    "behavioural_df = pd.merge(behavioural_df, word_nword_df, on=\"string\", how=\"left\").dropna().reset_index(drop=True)\n",
    "behavioural_df = behavioural_df.drop([\"freq\", \"participant\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c791ac-26e5-4ee4-929e-379e1b3248df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "behavioural_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837f7f89-8b4c-4cc5-9c2c-43dd3a512561",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Chossing a participant\n",
    "behavioural_df = behavioural_df.loc[behavioural_df[\"participant_id\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589c5731-ce20-4450-b237-0625c5196ab8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "behavioural_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc6ff4c",
   "metadata": {
    "id": "ff61f25e-7817-4f3f-a48f-d5a6666b0e75",
    "tags": []
   },
   "source": [
    "## Stan Model and Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27aa0a87-ed95-486a-beec-87a50c2f86ef",
   "metadata": {},
   "source": [
    "Compiling stan model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60550ee7-157d-4393-9f12-773eb947efce",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 93380,
     "status": "ok",
     "timestamp": 1651313346844,
     "user": {
      "displayName": "Arash Dadras",
      "userId": "05722346836148265544"
     },
     "user_tz": -270
    },
    "id": "c1b3627d-0ea2-49b6-86f0-7b098a5a16d6",
    "outputId": "4bc8643c-82c0-4fc9-99a0-7f232fa1eea4",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "rdm_model = cmdstanpy.CmdStanModel(model_name=model_config[\"model_name\"],\n",
    "                                   stan_file=stan_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75c8503-9cb2-40c0-ae79-e0e8d386a86f",
   "metadata": {},
   "source": [
    "Preparing model\"s inputs\n",
    "\n",
    "note that some inputs of data_dict might not be used depending on which model is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd38af62-fefa-4440-b250-f1717e0a2937",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N = len(behavioural_df)                                                    # For all models\n",
    "p = behavioural_df.loc[:, [\"word_prob\", \"non_word_prob\"]].to_numpy()       # predicted probabilites of words and non-words, for ANN-EAM models\n",
    "frequency = behavioural_df[\"zipf\"].to_numpy().astype(int)                  # zipf values, for models with non-decision time or drift modulation\n",
    "frequencyCondition = behavioural_df[\"category\"].replace([\"HF\", \"LF\", \"NW\"], [1, 2, 3]).to_numpy() # For models with conditional drift\n",
    "response = behavioural_df[\"response\"].to_numpy().astype(int)               # for all models\n",
    "rt = behavioural_df[\"rt\"].to_numpy()                                       # for all models\n",
    "minRT = behavioural_df[\"minRT\"].to_numpy()                                 # for all models\n",
    "RTbound = 0.1                                                              # for all models\n",
    "Number_Of_Participants = len(set(behavioural_df[\"participant_id\"]))\n",
    "\n",
    "threshold_priors = [2, 1]          # For all models with RDM\n",
    "ndt_priors = [0, 1];               # For models wtihout non-decision time modulation\n",
    "g_priors = [-2, 1]                 # For models wtih non-decision time modulation\n",
    "m_priors = [0, 0.5]                # For models wtih non-decision time modulation\n",
    "drift_priors = [1, 2]              # For models without drift mapping functions (non ANN-EAM models)\n",
    "alpha_priors = [0, 1]              # For models with drift mapping functions\n",
    "b_priors = [0, 1]                  # For models with drift mapping functions with asymptote modulation and linear models\n",
    "k_priors = [2, 1]                  # For models with sigmoid drift mapping functions (ANN-EAM models)\n",
    "\n",
    "# define input for the model\n",
    "data_dict = {\"N\": N,\n",
    "             \"response\": response,\n",
    "             \"rt\": rt,\n",
    "             \"minRT\": minRT,\n",
    "             \"RTbound\": RTbound,\n",
    "             \"frequency\": frequency,\n",
    "             \"frequencyCondition\": frequencyCondition,\n",
    "             \"threshold_priors\": threshold_priors,\n",
    "             \"ndt_priors\": ndt_priors,\n",
    "             \"g_priors\": g_priors,\n",
    "             \"m_priors\": m_priors,\n",
    "             \"drift_priors\": drift_priors,\n",
    "             \"p\": p,\n",
    "             \"alpha_priors\": alpha_priors,\n",
    "             \"b_priors\": b_priors,\n",
    "             \"k_priors\": k_priors,\n",
    "             }\n",
    "\n",
    "# set sampling parameters\n",
    "n_iter = 2000\n",
    "n_warmup = int(n_iter/2)\n",
    "n_sample = int(n_iter/2)\n",
    "n_chains = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4034d3d-99d8-43bf-b744-6b0608141c8d",
   "metadata": {},
   "source": [
    "Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ddd68e",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "edac015c-18f4-4ebf-8c3c-ecaf4b8e1d6a",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "fit = rdm_model.sample(data=data_dict,\n",
    "                       iter_sampling=n_sample, \n",
    "                       iter_warmup=n_warmup,\n",
    "                       chains=n_chains,\n",
    "                       output_dir=stan_output_dir,\n",
    "                       show_console=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2e1d2a-6f23-41c6-bf4d-360f7280b9e0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loading Model\n",
    "\n",
    "(In case model have been fitted before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a33d647",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "d781cdef-a1c6-4af1-940c-824398ec7d2b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "fit = cmdstanpy.from_csv(stan_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d7bfe3-f4b0-4c5e-b38a-da896fc9910a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b4b9f0",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "a8e1d56e-e7e4-4ca1-a0bd-5b34edf6ea44",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"***hmc diagnostics:\")\n",
    "print(fit.diagnose(), flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85eabdf-1647-4b68-a7d8-3f533ed7cd0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fit.diagnose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b033c45b",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "efa2a6ff-ad48-4c7e-a094-4c645923644e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = fit.summary()\n",
    "\n",
    "print(\"***DF: \")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0302aa3b",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "b33a48e1-8c3b-4668-9e74-ba74c58e3bec",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "counter = 0\n",
    "print(\"***Rhat > 1.01: \")\n",
    "for f in df[\"R_hat\"]:\n",
    "    if f >= 1.01 or f <= 0.9:\n",
    "        counter+=1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54606c2d",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "681ed2bf-2a28-4a8b-90d0-24b9fede846f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.loc[df[\"R_hat\"]>1.01].to_csv(\"Results/individual/logs/\" + model_config[\"model_name\"] + \"_rhat_log.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f94b558-e3ad-4a0a-b779-c389bc960922",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.loc[df[\"R_hat\"]>1.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0aa820a",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "a651e5b7-b7f1-4426-ae8e-f9e236eb6e91",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.loc[df[\"R_hat\"]>1.01].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b32ef5c",
   "metadata": {
    "id": "2743cc7e-7238-4f84-afe4-4b502770f62b",
    "tags": []
   },
   "source": [
    "## Check parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc740f54-db93-410c-9e26-282710ef2024",
   "metadata": {},
   "source": [
    "Parameters posterior plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67254033",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "48fc6630-74be-47a0-b387-ec99b9dc4b47",
    "tags": []
   },
   "outputs": [],
   "source": [
    "az.plot_posterior(fit, var_names=model_config[\"transf_params\"], hdi_prob=.95);\n",
    "plt.savefig(plots_path + \"Parameters.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e49f9c5",
   "metadata": {},
   "source": [
    "Loading model parameters for each trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133df71d",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "3539c070-29f7-422d-8c2e-1f7d44ef9246",
    "tags": []
   },
   "outputs": [],
   "source": [
    "drift_word_t = fit.stan_variables()[\"drift_word_t\"]\n",
    "drift_nonword_t = fit.stan_variables()[\"drift_nonword_t\"]\n",
    "if model_config[\"model_name\"] != \"RDM\":\n",
    "    threshold_t_word = fit.stan_variables()[\"threshold_t_word\"]\n",
    "    threshold_t_nonword = fit.stan_variables()[\"threshold_t_nonword\"]\n",
    "else:\n",
    "    threshold_t = fit.stan_variables()[\"threshold_t\"]\n",
    "ndt_t = fit.stan_variables()[\"ndt_t\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deaeee5d-28e4-4b67-9d90-6d8ba5d39423",
   "metadata": {},
   "source": [
    "#### Models mean parameters in different conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c645f86a",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "3a247d68-c3af-49ef-91fd-ba4ea221358d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "HF_condition_w = drift_word_t[:, behavioural_df[\"category\"]==\"HF\"]\n",
    "HF_condition_nw = drift_nonword_t[:, behavioural_df[\"category\"]==\"HF\"]\n",
    "LF_condition_w = drift_word_t[:, behavioural_df[\"category\"]==\"LF\"]\n",
    "LF_condition_nw = drift_nonword_t[:, behavioural_df[\"category\"]==\"LF\"]\n",
    "NW_condition_w = drift_word_t[:, behavioural_df[\"category\"]==\"NW\"]\n",
    "NW_condition_nw = drift_nonword_t[:, behavioural_df[\"category\"]==\"NW\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278e000d",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "deac1183-5610-4a19-8ff8-7bace8d12e7c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"HF words, word drift mean and std:\")\n",
    "print(np.mean(np.mean(HF_condition_w, axis=1)), np.std(np.mean(HF_condition_w, axis=1)))\n",
    "print(\"HF words, nonword drift mean and std:\")\n",
    "print(np.mean(np.mean(HF_condition_nw, axis=1)), np.std(np.mean(HF_condition_nw, axis=1)))\n",
    "print(\"LF words word drift mean and std:\")\n",
    "print(np.mean(np.mean(LF_condition_w, axis=1)), np.std(np.mean(LF_condition_w, axis=1)))\n",
    "print(\"LF words nonword drift mean and std:\")\n",
    "print(np.mean(np.mean(LF_condition_nw, axis=1)), np.std(np.mean(LF_condition_nw, axis=1)))\n",
    "print(\"NW words word drift mean and std:\")\n",
    "print(np.mean(np.mean(NW_condition_w, axis=1)), np.std(np.mean(NW_condition_w, axis=1)))\n",
    "print(\"NW words nonword drift mean and std:\")\n",
    "print(np.mean(np.mean(NW_condition_nw, axis=1)), np.std(np.mean(NW_condition_nw, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84308d46-e368-491f-8532-0f2b7b4f9966",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "3a247d68-c3af-49ef-91fd-ba4ea221358d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if model_config[\"model_name\"] != \"RDM\":\n",
    "    HF_condition_w = threshold_t_word[:, behavioural_df[\"category\"]==\"HF\"]\n",
    "    HF_condition_nw = threshold_t_nonword[:, behavioural_df[\"category\"]==\"HF\"]\n",
    "    LF_condition_w = threshold_t_word[:, behavioural_df[\"category\"]==\"LF\"]\n",
    "    LF_condition_nw = threshold_t_nonword[:, behavioural_df[\"category\"]==\"LF\"]\n",
    "    NW_condition_w = threshold_t_word[:, behavioural_df[\"category\"]==\"NW\"]\n",
    "    NW_condition_nw = threshold_t_nonword[:, behavioural_df[\"category\"]==\"NW\"]\n",
    "else:\n",
    "    HF_condition = threshold_t[:, behavioural_df[\"category\"]==\"HF\"]\n",
    "    LF_condition = threshold_t[:, behavioural_df[\"category\"]==\"LF\"]\n",
    "    NW_condition = threshold_t[:, behavioural_df[\"category\"]==\"NW\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d462da-a2d7-403e-9e79-1bcfd84251db",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "deac1183-5610-4a19-8ff8-7bace8d12e7c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if model_config[\"model_name\"] != \"RDM\":\n",
    "    print(\"HF words, word threshold mean and std:\")\n",
    "    print(np.mean(np.mean(HF_condition_w, axis=1)), np.std(np.mean(HF_condition_w, axis=1)))\n",
    "    print(\"HF words, nonword threshold mean and std:\")\n",
    "    print(np.mean(np.mean(HF_condition_nw, axis=1)), np.std(np.mean(HF_condition_nw, axis=1)))\n",
    "    print(\"LF words word threshold mean and std:\")\n",
    "    print(np.mean(np.mean(LF_condition_w, axis=1)), np.std(np.mean(LF_condition_w, axis=1)))\n",
    "    print(\"LF words nonword threshold mean and std:\")\n",
    "    print(np.mean(np.mean(LF_condition_nw, axis=1)), np.std(np.mean(LF_condition_nw, axis=1)))\n",
    "    print(\"NW words word threshold mean and std:\")\n",
    "    print(np.mean(np.mean(NW_condition_w, axis=1)), np.std(np.mean(NW_condition_w, axis=1)))\n",
    "    print(\"NW words nonword threshold mean and std:\")\n",
    "    print(np.mean(np.mean(NW_condition_nw, axis=1)), np.std(np.mean(NW_condition_nw, axis=1)))\n",
    "else:\n",
    "    print(\"HF words, threshold mean and std:\")\n",
    "    print(np.mean(np.mean(HF_condition, axis=1)), np.std(np.mean(HF_condition, axis=1)))\n",
    "    print(\"LF words, threshold mean and std:\")\n",
    "    print(np.mean(np.mean(LF_condition, axis=1)), np.std(np.mean(LF_condition, axis=1)))\n",
    "    print(\"NW words, word threshold mean and std:\")\n",
    "    print(np.mean(np.mean(NW_condition, axis=1)), np.std(np.mean(NW_condition, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914e74a9",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "06aceb06-2f53-47ae-b0f8-68d0c96f3cbf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "HF_condition = ndt_t[:, behavioural_df[\"category\"]==\"HF\"]\n",
    "LF_condition = ndt_t[:, behavioural_df[\"category\"]==\"LF\"]\n",
    "NW_condition = ndt_t[:, behavioural_df[\"category\"]==\"NW\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eacfbe0",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "c7ff4f51-0587-4f7a-bf79-7bc1fe0951e2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"HF words ndt_t mean and std:\")\n",
    "print(np.mean(np.mean(HF_condition, axis=1)), np.std(np.mean(HF_condition, axis=1)))\n",
    "print(\"LF words ndt_t mean and std:\")\n",
    "print(np.mean(np.mean(LF_condition, axis=1)), np.std(np.mean(LF_condition, axis=1)))\n",
    "print(\"Non Words ndt_t mean and std:\")\n",
    "print(np.mean(np.mean(NW_condition, axis=1)), np.std(np.mean(NW_condition, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d64f181-de50-4bec-ad6a-9f0c7c95cea5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Calculating metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beabf75-4cb8-49dc-b604-9f0adf32dfe4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "log_likelihood = fit.stan_variables()[\"log_lik\"]\n",
    "print(calculate_waic(log_likelihood))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a23772b-94de-40e6-88d6-f5a6aaefab64",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Simulating RDM with estimated parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b867e05c-ebda-4bc3-ae51-e340e337344f",
   "metadata": {},
   "source": [
    "Simulating RDM with estimated parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6786ed3-265f-4698-9a37-75d19e125806",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if model_config[\"model_name\"] != \"RDM\":\n",
    "    pp_rt, pp_response = random_rdm_2A(drift_word_t, drift_nonword_t, threshold_t_word, threshold_t_nonword, ndt_t, noise_constant=1, dt=0.001, max_rt=5)\n",
    "else:\n",
    "    pp_rt, pp_response = random_rdm_2A(drift_word_t, drift_nonword_t, threshold_t, threshold_t, ndt_t, noise_constant=1, dt=0.001, max_rt=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5ffc14-42ef-4338-9f7e-f6ad3851989c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predicted Data\n",
    "tmp1 = pd.DataFrame(pp_rt,\n",
    "                    index=pd.Index(np.arange(1, len(pp_rt)+1), name=\"sample\"),\n",
    "                    columns=pd.MultiIndex.from_product(([\"rt\"],\n",
    "                                                        np.arange(pp_rt.shape[1])),\n",
    "                                                        names=[\"variable\", \"trial\"]))\n",
    "tmp2 = pd.DataFrame(pp_response,\n",
    "                    index=pd.Index(np.arange(1, len(pp_response)+1), name=\"sample\"),\n",
    "                    columns=pd.MultiIndex.from_product(([\"response\"],\n",
    "                                                        np.arange(pp_response.shape[1])),\n",
    "                                                               names=[\"variable\", \"trial\"]))\n",
    "predictedData = pd.concat((tmp1, tmp2), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc68071a-3121-47da-94c5-bae5db334c5c",
   "metadata": {
    "id": "defea622-f638-4a0e-a269-937234d4a49f",
    "tags": []
   },
   "source": [
    "## RT Quantiles Posterior Predictions Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4378eb36-76cc-4a39-b2ed-643addccbc4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "quantiles = [.1, .3, .5, .7, .9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b02a18b-7bf1-40c1-b4e6-9db867ed685f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### All Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e9228d-9765-4f44-a0ef-c97b6fd2e4b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp_all_trials, pred_all_trials = get_dfs(behavioural_df, predictedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6726b938-0a09-4b6e-a072-f459566b1c10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_quantiles_ex = exp_all_trials[\"rt\"].quantile(quantiles)\n",
    "all_quantiles_pred = pred_all_trials.quantile(quantiles, axis=1).T\n",
    "all_predicted_bci = np.array([bci(all_quantiles_pred[x]) for x in quantiles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9684dde-03ae-4332-ae06-c1db2ed85527",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "\n",
    "ax.set_title(\"All Trials quantiles\", fontweight=\"bold\", size=14)\n",
    "ax.scatter(quantiles, all_quantiles_ex, color=\"black\", s=100)\n",
    "\n",
    "ax.fill_between(quantiles,\n",
    "                all_predicted_bci[:, 0],\n",
    "                all_predicted_bci[:, 1],\n",
    "                all_predicted_bci[:, 0] < all_predicted_bci[:, 1],  color = \"orange\", alpha=0.5)\n",
    "\n",
    "ax.set_xlabel(\"Quantiles\", fontsize=14)\n",
    "ax.set_xticks(quantiles)\n",
    "ax.set_xticklabels(quantiles)\n",
    "ax.set_ylabel(\"RT\", fontsize=14)\n",
    "for tick in ax.xaxis.get_major_ticks():\n",
    "    tick.label1.set_fontsize(12)\n",
    "for tick in ax.yaxis.get_major_ticks():\n",
    "    tick.label1.set_fontsize(12) \n",
    "\n",
    "sns.despine()\n",
    "plt.savefig(plots_path + \"PPC-Quantiles-All Trials.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b29ef22-e1ea-4549-b5fd-db69f2cc698f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### All Trials (word response vs non-word response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3e21b6-8fe0-4783-8100-78fc59ca10bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp_word_resp_all, pred_word_resp_all = get_dfs(behavioural_df, predictedData,\n",
    "                                                response=1)\n",
    "exp_nonword_resp_all, pred_nonword_resp_all = get_dfs(behavioural_df, predictedData,\n",
    "                                                      response=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7ff6be-9135-4ddf-bf21-43b130426f3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "word_quantiles_ex = exp_word_resp_all[\"rt\"].quantile(quantiles)\n",
    "nonword_quantiles_ex = exp_nonword_resp_all[\"rt\"].quantile(quantiles)\n",
    "\n",
    "word_quantiles_pred = pred_word_resp_all.quantile(quantiles, axis=1).T\n",
    "nonword_quantiles_pred = pred_nonword_resp_all.quantile(quantiles, axis=1).T\n",
    "\n",
    "word_predicted_bci = np.array([bci(word_quantiles_pred[x]) for x in quantiles])\n",
    "nonword_predicted_bci = np.array([bci(nonword_quantiles_pred[x]) for x in quantiles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7843d560-1a77-428a-9084-4a3dbdff62ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(25,6))\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "\n",
    "axes[0].set_title(\"Word trials quantiles\", fontweight=\"bold\", size=20)\n",
    "axes[1].set_title(\"Non Word trials quantiles\", fontweight=\"bold\", size=20)\n",
    "\n",
    "axes[0].scatter(quantiles, word_quantiles_ex, color=\"black\", s=100)\n",
    "axes[1].scatter(quantiles, nonword_quantiles_ex, color=\"black\", s=100)\n",
    "\n",
    "axes[0].fill_between(quantiles,\n",
    "                word_predicted_bci[:, 0],\n",
    "                word_predicted_bci[:, 1],\n",
    "                word_predicted_bci[:, 0] < word_predicted_bci[:, 1],  color = \"tomato\", alpha=0.5)\n",
    "\n",
    "axes[1].fill_between(quantiles,\n",
    "                nonword_predicted_bci[:, 0],\n",
    "                nonword_predicted_bci[:, 1],\n",
    "                nonword_predicted_bci[:, 0] < nonword_predicted_bci[:, 1],  color = \"powderblue\", alpha=0.5)\n",
    "\n",
    "for ax in axes:\n",
    "        ax.set_xlabel(\"Quantiles\", fontsize=16)\n",
    "        ax.set_xticks(quantiles)\n",
    "        ax.set_xticklabels(quantiles)\n",
    "        ax.set_ylabel(\"RT\", fontsize=16)\n",
    "        for tick in ax.xaxis.get_major_ticks():\n",
    "            tick.label1.set_fontsize(12)\n",
    "        for tick in ax.yaxis.get_major_ticks():\n",
    "            tick.label1.set_fontsize(12) \n",
    "\n",
    "sns.despine()\n",
    "plt.savefig(plots_path + \"PPC-Quantiles-All Trials-Word vs Nonword.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3f9bf4-b8a0-4ae2-a379-2181b7273a40",
   "metadata": {
    "tags": []
   },
   "source": [
    "### All trials (Correct Choice vs Incorrect Choice) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61a15b2-057b-4038-ad71-32cc17d5f2e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp_cor_choice_all, _ = get_dfs(behavioural_df, predictedData,\n",
    "                                accuracy=1)\n",
    "exp_incor_resp_all, _ = get_dfs(behavioural_df, predictedData,\n",
    "                                accuracy=0)\n",
    "pred_cor_choice_all = predictedData[\"rt\"][predictedData[\"response\"]==behavioural_df[\"label\"]]\n",
    "pred_incor_choice_all = predictedData[\"rt\"][predictedData[\"response\"]!=behavioural_df[\"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca4dfe2-00fe-4644-91e3-8fb946a95fac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cor_quantiles_ex = exp_cor_choice_all[\"rt\"].quantile(quantiles)\n",
    "incor_quantiles_ex = exp_incor_resp_all[\"rt\"].quantile(quantiles)\n",
    "\n",
    "cor_quantiles_pred = pred_cor_choice_all.quantile(quantiles, axis=1).T\n",
    "incor_quantiles_pred = pred_incor_choice_all.quantile(quantiles, axis=1).T\n",
    "\n",
    "cor_predicted_bci = np.array([bci(cor_quantiles_pred[x]) for x in quantiles])\n",
    "incor_predicted_bci = np.array([bci(incor_quantiles_pred[x]) for x in quantiles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfde7cd-d40a-40a2-af5e-752f6b2fea1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(25,6))\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "\n",
    "axes[0].set_title(\"Correct choice quantiles\", fontweight=\"bold\", size=20)\n",
    "axes[1].set_title(\"Incorrect choice quantiles\", fontweight=\"bold\", size=20)\n",
    "\n",
    "axes[0].scatter(quantiles, cor_quantiles_ex, color=\"black\", s=100)\n",
    "axes[1].scatter(quantiles, incor_quantiles_ex, color=\"black\", s=100)\n",
    "\n",
    "axes[0].fill_between(quantiles,\n",
    "                cor_predicted_bci[:, 0],\n",
    "                cor_predicted_bci[:, 1],\n",
    "                cor_predicted_bci[:, 0] < cor_predicted_bci[:, 1],  color = \"coral\", alpha=0.5)\n",
    "\n",
    "axes[1].fill_between(quantiles,\n",
    "                incor_predicted_bci[:, 0],\n",
    "                incor_predicted_bci[:, 1],\n",
    "                incor_predicted_bci[:, 0] < incor_predicted_bci[:, 1],  color = \"palegreen\", alpha=0.5)\n",
    "\n",
    "for ax in axes:\n",
    "        ax.set_xlabel(\"Quantiles\", fontsize=14)\n",
    "        ax.set_xticks(quantiles)\n",
    "        ax.set_xticklabels(quantiles)\n",
    "        ax.set_ylabel(\"RTs upper boundary\", fontsize=14)\n",
    "        for tick in ax.xaxis.get_major_ticks():\n",
    "            tick.label1.set_fontsize(12)\n",
    "        for tick in ax.yaxis.get_major_ticks():\n",
    "            tick.label1.set_fontsize(12) \n",
    "\n",
    "sns.despine()\n",
    "plt.savefig(plots_path + \"PPC-Quantiles-All Trials-Correct vs Incorrect.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdf2c17-b464-4994-bec4-36387026a780",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Conditional (HF, LF, NW trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d60ee5-9e44-4e7b-b22f-e9b85fb2fd93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp_HF_trials, pred_HF_trials = get_dfs(behavioural_df, predictedData,\n",
    "                                        category=\"HF\")\n",
    "exp_LF_trials, pred_LF_trials = get_dfs(behavioural_df, predictedData,\n",
    "                                        category=\"LF\")\n",
    "exp_NW_trials, pred_NW_trials = get_dfs(behavioural_df, predictedData,\n",
    "                                        category=\"NW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96001a51-55af-4f25-93c4-cdcc00556eb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# experiment Data quantile\n",
    "HF_quantile_ex = exp_HF_trials[\"rt\"].quantile(quantiles)\n",
    "LF_quantile_ex = exp_LF_trials[\"rt\"].quantile(quantiles)\n",
    "NW_quantile_ex = exp_NW_trials[\"rt\"].quantile(quantiles)\n",
    "\n",
    "# predicted data quantiles (for each sample)\n",
    "HF_quantile_pred = pred_HF_trials.quantile(quantiles, axis=1).T\n",
    "LF_quantile_pred = pred_LF_trials.quantile(quantiles, axis=1).T\n",
    "NW_quantile_pred = pred_NW_trials.quantile(quantiles, axis=1).T\n",
    "\n",
    "# predicted data quantiles bci\n",
    "HF_predicted_bci = np.array([bci(HF_quantile_pred[x]) for x in quantiles])\n",
    "LF_predicted_bci = np.array([bci(LF_quantile_pred[x]) for x in quantiles])\n",
    "NW_predicted_bci = np.array([bci(NW_quantile_pred[x]) for x in quantiles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e40fa75-a52a-45f9-8f44-b6097ff621e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,3 , figsize=(25,5))\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.5)\n",
    "\n",
    "axes[0].set_title(\"HF quantiles\", fontweight=\"bold\", size=20)\n",
    "axes[1].set_title(\"LF quantiles\", fontweight=\"bold\", size=20)\n",
    "axes[2].set_title(\"NW quantiles\", fontweight=\"bold\", size=20)\n",
    "\n",
    "axes[0].scatter(quantiles, HF_quantile_ex, color=\"black\", s=100)\n",
    "axes[1].scatter(quantiles, LF_quantile_ex, color=\"black\", s=100)\n",
    "axes[2].scatter(quantiles, NW_quantile_ex, color=\"black\", s=100)\n",
    "\n",
    "axes[0].fill_between(quantiles,\n",
    "                HF_predicted_bci[:, 0],\n",
    "                HF_predicted_bci[:, 1],\n",
    "                HF_predicted_bci[:, 0] < HF_predicted_bci[:, 1],  color = \"gold\", alpha=0.3)\n",
    "\n",
    "axes[1].fill_between(quantiles,\n",
    "                LF_predicted_bci[:, 0],\n",
    "                LF_predicted_bci[:, 1],\n",
    "                LF_predicted_bci[:, 0] < LF_predicted_bci[:, 1],  color = \"lightskyblue\", alpha=0.3)\n",
    "\n",
    "axes[2].fill_between(quantiles,\n",
    "                NW_predicted_bci[:, 0],\n",
    "                NW_predicted_bci[:, 1],\n",
    "                NW_predicted_bci[:, 0] < NW_predicted_bci[:, 1],  color = \"limegreen\", alpha=0.3)\n",
    "\n",
    "\n",
    "for ax in axes:\n",
    "        ax.set_xlabel(\"Quantiles\", fontsize=18)\n",
    "        ax.set_xticks(quantiles)\n",
    "        ax.set_xticklabels(quantiles)\n",
    "        ax.set_ylabel(\"RTs upper boundary\", fontsize=18)\n",
    "        for tick in ax.xaxis.get_major_ticks():\n",
    "                tick.label1.set_fontsize(13)\n",
    "        for tick in ax.yaxis.get_major_ticks():\n",
    "            tick.label1.set_fontsize(13) \n",
    "\n",
    "sns.despine()\n",
    "plt.savefig(plots_path + \"PPC-Quantiles-Conditional.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83c0620-716b-4051-b343-c1e711a969b4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Conditional (HF, LF, NW trials) for word response and nonword response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6f552f-53a6-4f8a-b00a-b05244c8323d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp_word_resp_HF, pred_word_resp_HF = get_dfs(behavioural_df, predictedData,\n",
    "                                              category=\"HF\", response=1)\n",
    "exp_word_resp_LF, pred_word_resp_LF = get_dfs(behavioural_df, predictedData,\n",
    "                                              category=\"LF\", response=1)\n",
    "exp_word_resp_NW, pred_word_resp_NW = get_dfs(behavioural_df, predictedData,\n",
    "                                              category=\"NW\", response=1)\n",
    "\n",
    "exp_nonword_resp_HF, pred_nonword_resp_HF = get_dfs(behavioural_df, predictedData,\n",
    "                                                    category=\"HF\", response=0)\n",
    "exp_nonword_resp_LF, pred_nonword_resp_LF = get_dfs(behavioural_df, predictedData,\n",
    "                                                    category=\"LF\", response=0)\n",
    "exp_nonword_resp_NW, pred_nonword_resp_NW = get_dfs(behavioural_df, predictedData,\n",
    "                                                    category=\"NW\", response=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39c6f5c-416a-4576-b75c-a2d9d3307b51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# experiment Data quantile\n",
    "HF_word_quantile_ex = exp_word_resp_HF[\"rt\"].quantile(quantiles)\n",
    "LF_word_quantile_ex = exp_word_resp_LF[\"rt\"].quantile(quantiles)\n",
    "NW_word_quantile_ex = exp_word_resp_NW[\"rt\"].quantile(quantiles)\n",
    "\n",
    "HF_nonword_quantile_ex = exp_nonword_resp_HF[\"rt\"].quantile(quantiles)\n",
    "LF_nonword_quantile_ex = exp_nonword_resp_LF[\"rt\"].quantile(quantiles)\n",
    "NW_nonword_quantile_ex = exp_nonword_resp_NW[\"rt\"].quantile(quantiles)\n",
    "\n",
    "# predicted data quantiles (for each sample)\n",
    "HF_word_quantile_pred = pred_word_resp_HF.quantile(quantiles, axis=1).T\n",
    "LF_word_quantile_pred = pred_word_resp_LF.quantile(quantiles, axis=1).T\n",
    "NW_word_quantile_pred = pred_word_resp_NW.quantile(quantiles, axis=1).T\n",
    "\n",
    "HF_nonword_quantile_pred = pred_nonword_resp_HF.quantile(quantiles, axis=1).T\n",
    "LF_nonword_quantile_pred = pred_nonword_resp_LF.quantile(quantiles, axis=1).T\n",
    "NW_nonword_quantile_pred = pred_nonword_resp_NW.quantile(quantiles, axis=1).T\n",
    "\n",
    "\n",
    "# predicted data quantiles bci\n",
    "HF_word_predicted_bci = np.array([bci(HF_word_quantile_pred[x]) for x in quantiles])\n",
    "LF_word_predicted_bci = np.array([bci(LF_word_quantile_pred[x]) for x in quantiles])\n",
    "NW_word_predicted_bci = np.array([bci(NW_word_quantile_pred[x]) for x in quantiles])\n",
    "\n",
    "HF_nonword_predicted_bci = np.array([bci(HF_nonword_quantile_pred[x]) for x in quantiles])\n",
    "LF_nonword_predicted_bci = np.array([bci(LF_nonword_quantile_pred[x]) for x in quantiles])\n",
    "NW_nonword_predicted_bci = np.array([bci(NW_nonword_quantile_pred[x]) for x in quantiles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafbc3a4-c5a0-4d3d-8038-dae9c80a4830",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,3 , figsize=(30,10))\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "\n",
    "axes[0][0].set_title(\"HF quantiles word choice\", fontweight=\"bold\", size=20)\n",
    "axes[0][1].set_title(\"LF quantiles word choice\", fontweight=\"bold\", size=20)\n",
    "axes[0][2].set_title(\"NW quantiles word choice\", fontweight=\"bold\", size=20)\n",
    "\n",
    "axes[1][0].set_title(\"HF quantiles non-word choice\", fontweight=\"bold\", size=20)\n",
    "axes[1][1].set_title(\"LF quantiles non-word choice\", fontweight=\"bold\", size=20)\n",
    "axes[1][2].set_title(\"NW quantiles non-word choice\", fontweight=\"bold\", size=20)\n",
    "\n",
    "axes[0][0].scatter(quantiles, HF_word_quantile_ex, color=\"black\", s=90)\n",
    "axes[0][1].scatter(quantiles, LF_word_quantile_ex, color=\"black\", s=90)\n",
    "axes[0][2].scatter(quantiles, NW_word_quantile_ex, color=\"black\", s=90)\n",
    "\n",
    "axes[1][0].scatter(quantiles, HF_nonword_quantile_ex, color=\"black\", s=90)\n",
    "axes[1][1].scatter(quantiles, LF_nonword_quantile_ex, color=\"black\", s=90)\n",
    "axes[1][2].scatter(quantiles, NW_nonword_quantile_ex, color=\"black\", s=90)\n",
    "\n",
    "\n",
    "axes[0][0].fill_between(quantiles,\n",
    "                HF_word_predicted_bci[:, 0],\n",
    "                HF_word_predicted_bci[:, 1],\n",
    "                HF_word_predicted_bci[:, 0] < HF_word_predicted_bci[:, 1],  color = \"gold\", alpha=0.3)\n",
    "\n",
    "axes[0][1].fill_between(quantiles,\n",
    "                LF_word_predicted_bci[:, 0],\n",
    "                LF_word_predicted_bci[:, 1],\n",
    "                LF_word_predicted_bci[:, 0] < LF_word_predicted_bci[:, 1],  color = \"lightskyblue\", alpha=0.3)\n",
    "\n",
    "axes[0][2].fill_between(quantiles,\n",
    "                NW_word_predicted_bci[:, 0],\n",
    "                NW_word_predicted_bci[:, 1],\n",
    "                NW_word_predicted_bci[:, 0] < NW_word_predicted_bci[:, 1],  color = \"limegreen\", alpha=0.3)\n",
    "\n",
    "\n",
    "axes[1][0].fill_between(quantiles,\n",
    "                HF_nonword_predicted_bci[:, 0],\n",
    "                HF_nonword_predicted_bci[:, 1],\n",
    "                HF_nonword_predicted_bci[:, 0] < HF_nonword_predicted_bci[:, 1],  color = \"gold\", alpha=0.3)\n",
    "\n",
    "axes[1][1].fill_between(quantiles,\n",
    "                LF_nonword_predicted_bci[:, 0],\n",
    "                LF_nonword_predicted_bci[:, 1],\n",
    "                LF_nonword_predicted_bci[:, 0] < LF_nonword_predicted_bci[:, 1],  color = \"lightskyblue\", alpha=0.3)\n",
    "\n",
    "axes[1][2].fill_between(quantiles,\n",
    "                NW_nonword_predicted_bci[:, 0],\n",
    "                NW_nonword_predicted_bci[:, 1],\n",
    "                NW_nonword_predicted_bci[:, 0] < NW_nonword_predicted_bci[:, 1],  color = \"limegreen\", alpha=0.3)\n",
    "\n",
    "\n",
    "for ax_d1 in axes:\n",
    "    for ax in ax_d1:\n",
    "        ax.set_xlabel(\"Quantiles\", fontsize=18)\n",
    "        ax.set_xticks(quantiles)\n",
    "        ax.set_xticklabels(quantiles)\n",
    "        ax.set_ylabel(\"RTs upper boundary\", fontsize=18)\n",
    "        for tick in ax.xaxis.get_major_ticks():\n",
    "                tick.label1.set_fontsize(14)\n",
    "        for tick in ax.yaxis.get_major_ticks():\n",
    "            tick.label1.set_fontsize(14) \n",
    "\n",
    "sns.despine()\n",
    "plt.savefig(plots_path + \"PPC-Quantiles-Conditional-Word vs Nonword.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055fca36-a949-4371-9a61-d81723328db4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Mean Accuracy and RT Posterior Prediction Checks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fce224e-c804-4e47-82b0-4ec2cec6ba95",
   "metadata": {},
   "source": [
    "### All trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10e0d51-8b1a-46f6-a440-19122b9fc003",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp_all_trials_rt, pred_all_trials_rt = get_dfs(behavioural_df, predictedData)\n",
    "exp_all_trials_resp, pred_all_trials_resp = get_dfs(behavioural_df, predictedData,\n",
    "                                                    pred_df_type=\"response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c16b54f-40f4-4973-b313-da2ac5e3a27c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_data_rt_mean = exp_all_trials_rt[\"rt\"].mean()\n",
    "all_pred_rt_mean = pred_all_trials_rt.mean(axis=1)\n",
    "\n",
    "all_data_resp_mean = exp_all_trials_resp[\"response\"].mean()\n",
    "all_pred_resp_mean = pred_all_trials_resp.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa3cb73-0684-4a86-baaa-554ee0ae1333",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2 , figsize=(12, 4))\n",
    "plt.subplots_adjust(wspace=0.3, hspace=0.5)\n",
    "\n",
    "axes[0].set_title(\"All trials mean RT\", fontweight=\"bold\", size=16)\n",
    "axes[1].set_title(\"All trials mean Response\", fontweight=\"bold\", size=16)\n",
    "\n",
    "plot_mean_posterior(all_pred_rt_mean, all_data_rt_mean, axes[0])\n",
    "plot_mean_posterior(all_pred_resp_mean, all_data_resp_mean, axes[1])\n",
    "\n",
    "axes[0].set_xlabel(\"RT\", fontsize=16)\n",
    "axes[1].set_xlabel(\"Response\", fontsize=16)\n",
    "\n",
    "for ax in axes:\n",
    "        ax.set_ylabel(\"Density\", fontsize=16)\n",
    "        for tick in ax.xaxis.get_major_ticks():\n",
    "            tick.label1.set_fontsize(12)\n",
    "        for tick in ax.yaxis.get_major_ticks():\n",
    "            tick.label1.set_fontsize(12)\n",
    "            \n",
    "plt.savefig(plots_path + \"PPC-Mean Accuracy and RT-All trials.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f40574c-977b-4269-bb1e-528eaa139c04",
   "metadata": {
    "tags": []
   },
   "source": [
    "### All Trials (correct choice vs incorrect choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432ce948-7da0-4ea9-b05a-ff496baa2c88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp_cor_all_trials_rt, pred_cor_all_trials_rt = get_dfs(behavioural_df, predictedData,\n",
    "                                                        accuracy=1)\n",
    "exp_incor_all_trials_rt, pred_incor_all_trials_rt = get_dfs(behavioural_df, predictedData,\n",
    "                                                            accuracy=0)\n",
    "\n",
    "exp_cor_all_trials_resp, pred_cor_all_trials_resp = get_dfs(behavioural_df, predictedData,\n",
    "                                                            accuracy=1, pred_df_type=\"response\")\n",
    "exp_incor_all_trials_resp, pred_incor_all_trials_resp = get_dfs(behavioural_df, predictedData,\n",
    "                                                                accuracy=0, pred_df_type=\"response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3712c389-4ee9-49ba-a1c1-776ef4117124",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_trials_cor_rt_mean = exp_cor_all_trials_rt[\"rt\"].mean()\n",
    "all_pred_cor_rt_mean = pred_cor_all_trials_rt.mean(axis=1)\n",
    "\n",
    "all_trials_incor_rt_mean = exp_incor_all_trials_rt[\"rt\"].mean()\n",
    "all_pred_incor_rt_mean = pred_incor_all_trials_rt.mean(axis=1)\n",
    "\n",
    "\n",
    "all_data_cor_resp_mean = exp_cor_all_trials_resp[\"response\"].mean()\n",
    "all_pred_cor_resp_mean = pred_cor_all_trials_resp.mean(axis=1)\n",
    "\n",
    "all_data_incor_resp_mean = exp_incor_all_trials_resp[\"response\"].mean()\n",
    "all_pred_incor_resp_mean = pred_incor_all_trials_resp.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e977529c-6748-42ff-bcc7-4410ced61b62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,2 , figsize=(12,10))\n",
    "plt.subplots_adjust(wspace=0.3, hspace=0.5)\n",
    "\n",
    "axes[0][0].set_title(\"Correct trials mean RT\", fontweight=\"bold\", size=16)\n",
    "axes[0][1].set_title(\"Correct trials mean Response\", fontweight=\"bold\", size=16)\n",
    "axes[1][0].set_title(\"Incorrect trials mean RT\", fontweight=\"bold\", size=16)\n",
    "axes[1][1].set_title(\"Incorrect trials mean Response\", fontweight=\"bold\", size=16)\n",
    "\n",
    "plot_mean_posterior(all_pred_cor_rt_mean, all_trials_cor_rt_mean, axes[0][0])\n",
    "plot_mean_posterior(all_pred_cor_resp_mean, all_data_cor_resp_mean, axes[0][1])\n",
    "\n",
    "plot_mean_posterior(all_pred_incor_rt_mean, all_trials_incor_rt_mean, axes[1][0])\n",
    "plot_mean_posterior(all_pred_incor_resp_mean, all_data_incor_resp_mean, axes[1][1])\n",
    "\n",
    "for ax in axes:\n",
    "        ax[0].set_xlabel(\"RT\", fontsize=15)\n",
    "        ax[1].set_xlabel(\"Accuracy\", fontsize=15)\n",
    "        ax[0].set_ylabel(\"Density\", fontsize=15)\n",
    "        ax[1].set_ylabel(\"Density\", fontsize=15)\n",
    "        for tick in ax[0].xaxis.get_major_ticks():\n",
    "            tick.label1.set_fontsize(13)\n",
    "        for tick in ax[0].yaxis.get_major_ticks():\n",
    "            tick.label1.set_fontsize(13)\n",
    "        for tick in ax[1].xaxis.get_major_ticks():\n",
    "            tick.label1.set_fontsize(13)\n",
    "        for tick in ax[1].yaxis.get_major_ticks():\n",
    "            tick.label1.set_fontsize(13) \n",
    "\n",
    "plt.savefig(plots_path + \"PPC-Mean Accuracy and RT-All trials-Correct vs Incorrect.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a07ed4c-9890-45d5-ba73-fe337d76d89c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Conditional (HF, LF, NW trials) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321c23f2-b50a-44cf-81ad-1808fcb55376",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp_HF_trials_rt, pred_HF_trials_rt = get_dfs(behavioural_df, predictedData,\n",
    "                                              category=\"HF\")\n",
    "exp_LF_trials_rt, pred_LF_trials_rt = get_dfs(behavioural_df, predictedData,\n",
    "                                              category=\"LF\")\n",
    "exp_NW_trials_rt, pred_NW_trials_rt = get_dfs(behavioural_df, predictedData,\n",
    "                                              category=\"NW\")\n",
    "\n",
    "exp_HF_trials_resp, pred_HF_trials_resp = get_dfs(behavioural_df, predictedData,\n",
    "                                                  category=\"HF\", pred_df_type=\"response\")\n",
    "exp_LF_trials_resp, pred_LF_trials_resp = get_dfs(behavioural_df, predictedData,\n",
    "                                                  category=\"LF\", pred_df_type=\"response\")\n",
    "exp_NW_trials_resp, pred_NW_trials_resp = get_dfs(behavioural_df, predictedData,\n",
    "                                                  category=\"NW\", pred_df_type=\"response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47bd273-56cd-45ab-8d2d-b78dd0b5ff44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "HF_data_rt_mean = exp_HF_trials_rt[\"rt\"].mean()\n",
    "LF_data_rt_mean = exp_LF_trials_rt[\"rt\"].mean()\n",
    "NW_data_rt_mean = exp_NW_trials_rt[\"rt\"].mean()\n",
    "\n",
    "HF_pred_rt_mean = pred_HF_trials_rt.mean(axis=1)\n",
    "LF_pred_rt_mean = pred_LF_trials_rt.mean(axis=1)\n",
    "NW_pred_rt_mean = pred_NW_trials_rt.mean(axis=1)\n",
    "\n",
    "\n",
    "HF_data_resp_mean = exp_HF_trials_resp[\"response\"].mean()\n",
    "LF_data_resp_mean = exp_LF_trials_resp[\"response\"].mean()\n",
    "NW_data_resp_mean = exp_NW_trials_resp[\"response\"].mean()\n",
    "\n",
    "HF_pred_resp_mean = pred_HF_trials_resp.mean(axis=1)\n",
    "LF_pred_resp_mean = pred_LF_trials_resp.mean(axis=1)\n",
    "NW_pred_resp_mean = pred_NW_trials_resp.mean(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1425b94-db06-4d73-a4d5-ce1b342856a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3,2 , figsize=(12,15))\n",
    "plt.subplots_adjust(wspace=0.3, hspace=0.5)\n",
    "\n",
    "axes[0][0].set_title(\"HF mean RT\", fontweight=\"bold\", size=16)\n",
    "axes[0][1].set_title(\"HF mean Response\", fontweight=\"bold\", size=16)\n",
    "axes[1][0].set_title(\"LF mean RT\", fontweight=\"bold\", size=16)\n",
    "axes[1][1].set_title(\"LF mean Response\", fontweight=\"bold\", size=16)\n",
    "axes[2][0].set_title(\"NW mean RT\", fontweight=\"bold\", size=16)\n",
    "axes[2][1].set_title(\"NW mean Response\", fontweight=\"bold\", size=16)\n",
    "\n",
    "plot_mean_posterior(HF_pred_rt_mean, HF_data_rt_mean, axes[0][0])\n",
    "plot_mean_posterior(HF_pred_resp_mean, HF_data_resp_mean, axes[0][1])\n",
    "\n",
    "plot_mean_posterior(LF_pred_rt_mean, LF_data_rt_mean, axes[1][0])\n",
    "plot_mean_posterior(LF_pred_resp_mean, LF_data_resp_mean, axes[1][1])\n",
    "\n",
    "plot_mean_posterior(NW_pred_rt_mean, NW_data_rt_mean, axes[2][0])\n",
    "plot_mean_posterior(NW_pred_resp_mean, NW_data_resp_mean, axes[2][1])\n",
    "\n",
    "for ax in axes:\n",
    "        ax[0].set_xlabel(\"RT\", fontsize=15)\n",
    "        ax[1].set_xlabel(\"Accuracy\", fontsize=15)\n",
    "        ax[0].set_ylabel(\"Density\", fontsize=15)\n",
    "        ax[1].set_ylabel(\"Density\", fontsize=15)\n",
    "        for tick in ax[0].xaxis.get_major_ticks():\n",
    "            tick.label1.set_fontsize(13)\n",
    "        for tick in ax[0].yaxis.get_major_ticks():\n",
    "            tick.label1.set_fontsize(13)\n",
    "        for tick in ax[1].xaxis.get_major_ticks():\n",
    "            tick.label1.set_fontsize(13)\n",
    "        for tick in ax[1].yaxis.get_major_ticks():\n",
    "            tick.label1.set_fontsize(13) \n",
    "\n",
    "plt.savefig(plots_path + \"PPC-Mean Accuracy and RT-Conditional.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6124c569-b5c7-4192-a1e2-cabe6856c323",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d740a45d-3753-4152-8256-2dbda204a17b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Estimation_Hier.ipynb",
   "version": ""
  },
  "kernelspec": {
   "display_name": "stan",
   "language": "python",
   "name": "stan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
